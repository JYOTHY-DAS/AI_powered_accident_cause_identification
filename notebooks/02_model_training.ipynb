{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import scipy\n",
    "from scipy.sparse import csr_matrix  # For reconstructing the sparse matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loaded = np.load(\"X_sparse.npz\")\n",
    "# from scipy.sparse import csr_matrix\n",
    "X = csr_matrix((X_loaded['data'], X_loaded['indices'], X_loaded['indptr']), shape=X_loaded['shape']) # Reconstructing X from the compressed file\n",
    "y_primary= pd.read_csv(\"y_primary.csv\")\n",
    "y_secondary= pd.read_csv(\"y_secondary.csv\")\n",
    "y_risk= pd.read_csv(\"y_risk.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Supervised Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train_primary, y_test_primary = train_test_split(X, y_primary, test_size=0.2, random_state=42)\n",
    "_, _, y_train_secondary, y_test_secondary = train_test_split(X, y_secondary, test_size=0.2, random_state=42)\n",
    "_, _, y_train_risk, y_test_risk = train_test_split(X, y_risk, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert sparse matrix to dense, then to DataFrame\n",
    "X_test_df = pd.DataFrame(X_test.toarray())  # Convert CSR matrix to dense before saving\n",
    "X_test_df.to_csv('X_test.csv', index=False)\n",
    "\n",
    "# Save target test datasets\n",
    "y_test_primary.to_csv('y_test_primary.csv', index=False)\n",
    "y_test_secondary.to_csv('y_test_secondary.csv', index=False)\n",
    "y_test_risk.to_csv('y_test_risk.csv', index=False)\n",
    "\n",
    "# Convert target variables to NumPy arrays before fitting models\n",
    "y_train_primary = y_train_primary.values.ravel()\n",
    "y_train_secondary = y_train_secondary.values.ravel()\n",
    "y_train_risk = y_train_risk.values.ravel()\n",
    "\n",
    "# Train models\n",
    "model_primary = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model_primary.fit(X_train, y_train_primary)\n",
    "\n",
    "model_secondary = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model_secondary.fit(X_train, y_train_secondary)\n",
    "\n",
    "model_risk = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model_risk.fit(X_train, y_train_risk)\n",
    "\n",
    "# Save models\n",
    "joblib.dump(model_primary, 'accident_model_primary.pkl')\n",
    "joblib.dump(model_secondary, 'accident_model_secondary.pkl')\n",
    "joblib.dump(model_risk, 'accident_model_risk.pkl')\n",
    "\n",
    "print(\"All models trained and saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
