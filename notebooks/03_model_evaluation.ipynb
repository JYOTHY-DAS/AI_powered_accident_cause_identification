{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load trained models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_primary \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccident_model_primary.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model_secondary \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccident_model_secondary.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m model_risk \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccident_model_risk.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "# Load trained models\n",
    "model_primary = joblib.load('accident_model_primary.pkl')\n",
    "model_secondary = joblib.load('accident_model_secondary.pkl')\n",
    "model_risk = joblib.load('accident_model_risk.pkl')\n",
    "\n",
    "# Load encoders\n",
    "label_encoder_primary = joblib.load('label_encoder_primary.pkl')\n",
    "label_encoder_secondary = joblib.load('label_encoder_secondary.pkl')\n",
    "label_encoder_risk = joblib.load('label_encoder_risk.pkl')\n",
    "\n",
    "# Load vectorizer\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "\n",
    "#Load X_test and y_test\n",
    "X_test_file=pd.read_csv('X_test.csv')\n",
    "X_test = X_test_file.to_numpy()  # Convert to NumPy array\n",
    "\n",
    "y_test_primary=pd.read_csv('y_test_primary.csv')\n",
    "y_test_secondary=pd.read_csv('y_test_secondary.csv')\n",
    "y_test_risk=pd.read_csv('y_test_risk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate primary cause model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Cause Model Evaluation:\n",
      "Accuracy: 1.0\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Distracted driving       1.00      1.00      1.00       457\n",
      "      Drunk driving       1.00      1.00      1.00       433\n",
      "      Over-speeding       1.00      1.00      1.00       472\n",
      "        Overloading       1.00      1.00      1.00       464\n",
      "  Red light jumping       1.00      1.00      1.00       431\n",
      "    Road conditions       1.00      1.00      1.00       414\n",
      "         Tailgating       1.00      1.00      1.00       474\n",
      "Vehicle malfunction       1.00      1.00      1.00       451\n",
      " Wrong side driving       1.00      1.00      1.00       404\n",
      "\n",
      "           accuracy                           1.00      4000\n",
      "          macro avg       1.00      1.00      1.00      4000\n",
      "       weighted avg       1.00      1.00      1.00      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_primary = model_primary.predict(X_test) \n",
    "\n",
    "print(\"Primary Cause Model Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_primary, y_pred_primary))\n",
    "print(classification_report(y_test_primary, y_pred_primary, target_names=label_encoder_primary.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Secondary Cause Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary Cause Model Evaluation:\n",
      "Accuracy: 0.70725\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "Drunk Driving Violation       1.00      0.60      0.75       323\n",
      "       Helmet Violation       0.51      0.80      0.62       303\n",
      " Mobile Phone Violation       1.00      0.64      0.78       330\n",
      "           No Violation       0.93      0.63      0.75       602\n",
      "  Overloading Violation       0.99      0.59      0.74       341\n",
      "     Seatbelt Violation       0.49      0.95      0.65       859\n",
      "       Signal Violation       0.88      0.71      0.78       315\n",
      "     Speeding Violation       1.00      0.61      0.76       326\n",
      "   Tailgating Violation       0.99      0.53      0.69       330\n",
      "   Wrong Lane Violation       0.82      0.70      0.75       271\n",
      "\n",
      "               accuracy                           0.71      4000\n",
      "              macro avg       0.86      0.68      0.73      4000\n",
      "           weighted avg       0.82      0.71      0.72      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_secondary = model_secondary.predict(X_test)  # Convert sparse to dense\n",
    "print(\"Secondary Cause Model Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_secondary, y_pred_secondary))\n",
    "print(classification_report(y_test_secondary, y_pred_secondary, target_names=label_encoder_secondary.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Risk Factor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Risk Factor Model Evaluation:\n",
      "Accuracy: 0.7175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.72      1.00      0.84      2870\n",
      "         Low       0.00      0.00      0.00       728\n",
      "      Medium       0.00      0.00      0.00       402\n",
      "\n",
      "    accuracy                           0.72      4000\n",
      "   macro avg       0.24      0.33      0.28      4000\n",
      "weighted avg       0.51      0.72      0.60      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ICT Academy\\Internship\\AI_powered_accident_cause_identification\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\ICT Academy\\Internship\\AI_powered_accident_cause_identification\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\ICT Academy\\Internship\\AI_powered_accident_cause_identification\\notebooks\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_risk = model_risk.predict(X_test)\n",
    "\n",
    "print(\"\\n Risk Factor Model Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_risk, y_pred_risk))\n",
    "print(classification_report(y_test_risk, y_pred_risk, target_names=label_encoder_risk.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
